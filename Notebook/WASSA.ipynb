{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "381155c6-98ba-4153-b066-5f47708b23fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'text', 'label', 'intensity'],\n",
      "    num_rows: 2470\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bba9fef8a394f6ebad4499077cb127c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2470 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'text', 'label', 'intensity'],\n",
      "    num_rows: 2466\n",
      "})\n",
      "Train Dataset: Dataset({\n",
      "    features: ['id', 'text', 'label', 'intensity'],\n",
      "    num_rows: 1972\n",
      "})\n",
      "Test Dataset: Dataset({\n",
      "    features: ['id', 'text', 'label', 'intensity'],\n",
      "    num_rows: 494\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417d473eefe14d249b2366acb3898bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ef3880ae6e49d49e2dabb5abfa960e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/494 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: Dataset({\n",
      "    features: ['input', 'labels', 'output'],\n",
      "    num_rows: 1972\n",
      "})\n",
      "Validation Dataset: Dataset({\n",
      "    features: ['input', 'labels', 'output'],\n",
      "    num_rows: 494\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "#load train data\n",
    "import pandas as pd\n",
    "cols = ['id', 'text', 'label', 'intensity']\n",
    "path = \"https://raw.githubusercontent.com/vinayakumarr/WASSA-2017/refs/heads/master/wassa/data/training/\"\n",
    "anger_train = pd.read_csv(StringIO(requests.get(path + 'anger-ratings-0to1.train.txt').text), header=None, sep='\\t', names=cols, index_col=0)\n",
    "fear_train = pd.read_csv(StringIO(requests.get(path + 'fear-ratings-0to1.train').text), header=None, sep='\\t', names=cols, index_col=0)\n",
    "sad_train = pd.read_csv(StringIO(requests.get(path + 'sadness-ratings-0to1.train.txt').text), header=None, sep='\\t', names=cols, index_col=0)\n",
    "joy_train = pd.read_csv(StringIO(requests.get(path + 'joy-ratings-0to1.train.txt').text), header=None, sep='\\t', names=cols, index_col=0)\n",
    "\n",
    "dataset = pd.concat([anger_train, fear_train, sad_train, joy_train], axis=0)\n",
    "\n",
    "# Reset index for the combined DataFrame (optional)\n",
    "dataset.reset_index(inplace=True)\n",
    "\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "# Inspect the dataset\n",
    "print(dataset)\n",
    "\n",
    "def is_valid_intensity(example):\n",
    "    if example['intensity'] is not None:\n",
    "        #print(example['intensity'])\n",
    "        try: \n",
    "            k = float(example['intensity'])\n",
    "            return True\n",
    "        except:\n",
    "        \n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Filter the dataset\n",
    "dataset = dataset.filter(is_valid_intensity)\n",
    "print(dataset)\n",
    "# Split the shuffled dataset into train and test sets\n",
    "train_test_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Access the train and test datasets\n",
    "train_data = train_test_split['train']\n",
    "val_data = train_test_split['test']\n",
    "\n",
    "# Inspect the datasets\n",
    "print(\"Train Dataset:\", train_data)\n",
    "print(\"Test Dataset:\", val_data)\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig\n",
    "#from roberta import RobertaForSequenceClassification\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "# Log in using your Hugging Face token\n",
    "login(\"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\")\n",
    "\n",
    "model_name ='meta-llama/Llama-2-7b-hf'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.model_max_length = 1000\n",
    "\n",
    "\n",
    "\n",
    "from datasets import DatasetDict\n",
    "\n",
    "\n",
    "\n",
    "# Define the prompt generation function\n",
    "def generate_prompt(data_point):\n",
    "    \"\"\"\n",
    "    Generates a prompt for a given data point to evaluate intensity.\n",
    "    Args:\n",
    "        data_point (dict): A dictionary containing 'label' and 'intensity' keys.\n",
    "    Returns:\n",
    "        str: The formatted prompt as a string.\n",
    "    \"\"\"\n",
    "    return f\"\"\"### Instruction: You are given a label and intensity value. Determine the intensity on a scale from 0 to 1 for the given input.\n",
    "                ### Input: {data_point['text']}.\n",
    "                ### Label: {data_point['label']}.\n",
    "                ### Output: The intensity is \"\"\"\n",
    "\n",
    "\n",
    "# Function to add 'input', 'labels', and 'output' columns\n",
    "def add_label_column(example):\n",
    "    #print(example['intensity'])\n",
    "    num = float(example['intensity'])  # Convert intensity to float\n",
    "    example['input'] = generate_prompt(example)  # Add prompt as 'input'\n",
    "    example['labels'] = num  # Add intensity as labels\n",
    "    example['output'] = str(num)  # Add intensity as string output\n",
    "    return example\n",
    "\n",
    "# Map the function over train and validation datasets\n",
    "train_data = train_data.map(add_label_column)\n",
    "val_data = val_data.map(add_label_column)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_remove = ['label', 'intensity','id', 'text']  # Update as per your dataset\n",
    "train_data = train_data.remove_columns(columns_to_remove)\n",
    "val_data = val_data.remove_columns(columns_to_remove)\n",
    "\n",
    "# Inspect the updated datasets\n",
    "print(\"Train Dataset:\", train_data)\n",
    "print(\"Validation Dataset:\", val_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8befa8a7-ae4b-48d2-b695-fa2dfccdf662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"### Instruction: You are given a label and intensity value. Determine the intensity on a scale from 0 to 1 for the given input.\\n                ### Input: you know cyran still hasn't done makeup based on jeongguk's tiddy like i suggested and i'm #offended.\\n                ### Label: anger.\\n                ### Output: The intensity is \",\n",
       " 0.479,\n",
       " '0.479')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['input'][2], train_data['labels'][2], train_data['output'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894cb65d-3402-4fc3-8353-29ab723ac241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('### Instruction: You are given a label and intensity value. Determine the intensity on a scale from 0 to 1 for the given input.\\n                ### Input: so ef whichever butt wipe pulled the fire alarm in davis bc I was sound asleep #pissed  #upset #tired #sad #tired #hangry ######.\\n                ### Label: anger.\\n                ### Output: The intensity is ',\n",
       " 0.771,\n",
       " '0.771')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data['input'][2], val_data['labels'][2], val_data['output'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb1666e-01f9-4002-8dfa-fefbc935b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator.modeling import PredictorCausalLM\n",
    "from generator.collator import DataCollator\n",
    "from generator import metrics\n",
    "from generator.training import GenTrainer\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)  # Load configuration\n",
    "config.dense_representation = 10 \n",
    "config.pad_token_id = tokenizer.pad_token_id\n",
    "config.nub_of_token_generation = 59\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ad5915-d62d-43c3-87d5-8d8db5c01562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93112a324a7442269b7ce134635a0380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PredictorCausalLM(config, num_labels=1)  # Instantiate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d9aed5-8b78-4cb7-bdb4-906d0435c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leader\n",
    "\n",
    "leader.PEFT(model, method='column', rank=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d87611e2-50ff-41b7-a575-346a7de64911",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollator(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60b04dbe-f6f9-4d7a-84b8-9466978b7722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import time\n",
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='dir',\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.00,\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=2,\n",
    "    save_steps=10000000,\n",
    "    logging_steps=200,\n",
    "\n",
    "    load_best_model_at_end=False,\n",
    "    lr_scheduler_type=\"cosine\",  # You can choose from 'linear', 'cosine', 'cosine_with_restarts', 'polynomial', etc.\n",
    "    warmup_steps=200,\n",
    ")\n",
    "\n",
    "compute_metrics = metrics.RegressionMetrics(tokenizer)\n",
    "trainer = GenTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    max_steps_for_sampling=500,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304e9528-a34e-48f7-a8e3-f5857762328d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1640' max='1640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1640/1640 1:33:44, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>R2</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman's rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>85.707900</td>\n",
       "      <td>8.325174</td>\n",
       "      <td>0.099858</td>\n",
       "      <td>0.015980</td>\n",
       "      <td>0.126411</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.551153</td>\n",
       "      <td>0.767732</td>\n",
       "      <td>0.769222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>29.600600</td>\n",
       "      <td>7.841394</td>\n",
       "      <td>0.102324</td>\n",
       "      <td>0.016004</td>\n",
       "      <td>0.126507</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>0.550475</td>\n",
       "      <td>0.798979</td>\n",
       "      <td>0.771356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>23.508500</td>\n",
       "      <td>8.753027</td>\n",
       "      <td>0.087765</td>\n",
       "      <td>0.011939</td>\n",
       "      <td>0.109265</td>\n",
       "      <td>0.018219</td>\n",
       "      <td>0.664654</td>\n",
       "      <td>0.820149</td>\n",
       "      <td>0.816306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>17.186800</td>\n",
       "      <td>9.821688</td>\n",
       "      <td>0.087538</td>\n",
       "      <td>0.011739</td>\n",
       "      <td>0.108349</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>0.670258</td>\n",
       "      <td>0.819185</td>\n",
       "      <td>0.803115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>11.040200</td>\n",
       "      <td>13.443336</td>\n",
       "      <td>0.089071</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>0.110347</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>0.657980</td>\n",
       "      <td>0.813651</td>\n",
       "      <td>0.807939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>7.970700</td>\n",
       "      <td>14.633918</td>\n",
       "      <td>0.084235</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.105728</td>\n",
       "      <td>0.044534</td>\n",
       "      <td>0.686014</td>\n",
       "      <td>0.828310</td>\n",
       "      <td>0.820075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>7.181500</td>\n",
       "      <td>15.307802</td>\n",
       "      <td>0.084472</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.105652</td>\n",
       "      <td>0.046559</td>\n",
       "      <td>0.686467</td>\n",
       "      <td>0.830503</td>\n",
       "      <td>0.823756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>6.866600</td>\n",
       "      <td>16.018980</td>\n",
       "      <td>0.084020</td>\n",
       "      <td>0.011064</td>\n",
       "      <td>0.105186</td>\n",
       "      <td>0.044534</td>\n",
       "      <td>0.689227</td>\n",
       "      <td>0.831257</td>\n",
       "      <td>0.823811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1640, training_loss=23.224490803044016, metrics={'train_runtime': 5627.2303, 'train_samples_per_second': 7.009, 'train_steps_per_second': 0.291, 'total_flos': 103615352586240.0, 'train_loss': 23.224490803044016, 'epoch': 19.76595744680851})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aec7b6-0bc9-4cb3-9012-c507990dd1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
