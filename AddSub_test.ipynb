{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0219d6aa-3de4-4f21-b48d-15733d960cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer, GenerationConfig\n",
    "from peft import LoraConfig, get_peft_model, PeftConfig, PeftModel, prepare_model_for_kbit_training, AdaLoraConfig, AdaLoraConfig\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_data = load_dataset('json', data_files='https://raw.githubusercontent.com/AGI-Edgerunners/LLM-Adapters/refs/heads/main/dataset/AddSub/addsub_1.json')['train']\n",
    "test_data = load_dataset('json', data_files='https://raw.githubusercontent.com/AGI-Edgerunners/LLM-Adapters/refs/heads/main/dataset/AddSub/test.json')['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b50ca3-cc20-4ff2-8e52-254456898b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/kowsher/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig\n",
    "#from roberta import RobertaForSequenceClassification\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "# Log in using your Hugging Face token\n",
    "login(\"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\")\n",
    "\n",
    "model_name = \"HuggingFaceTB/SmolLM-135M-Instruct\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43340348-09f6-4d63-b02c-915c006721b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "train_data = train_data.rename_column(\"question\", \"input\")\n",
    "\n",
    "test_data = test_data.remove_columns('input')\n",
    "test_data = test_data.rename_column(\"instruction\", \"input\")\n",
    "\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    #print(data_point)\n",
    "    # sorry about the formatting disaster gotta move fast\n",
    "    return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "                ### Instruction: {data_point}\n",
    "                ### Response: \"\"\" # noqa: E501\n",
    "\n",
    "\n",
    "# Assuming `dataset` is your DatasetDict\n",
    "def add_label_column(example):\n",
    "    total_length = 19\n",
    "    num = float(example['answer'])\n",
    "\n",
    "    #formatted_num = str(num) + tokenizer.pad_token * padding_length\n",
    "\n",
    "    # Add labels and outputs to the example\n",
    "    example['labels'] = float(example['answer'])\n",
    "    example['output'] = str(num)\n",
    "    example['input'] = generate_prompt(example['input'])\n",
    "\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab3e4f7-5115-4946-bfe4-c14dd36c1e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'chain-of-thought', 'pred', 'answer', 'labels', 'output'],\n",
      "    num_rows: 395\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f33ed82f5045378fb0fb350198df22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/395 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'output', 'answer', 'labels'],\n",
      "    num_rows: 395\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to add the 'label' column\n",
    "train_data = train_data.map(add_label_column)\n",
    "#train_data = train_data.remove_columns('input')\n",
    "# Verify the changes\n",
    "print(train_data)\n",
    "\n",
    "test_data = test_data.map(add_label_column)\n",
    "#test_datasets = test_datasets.remove_columns('input')\n",
    "# Verify the changes\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b14d170-41cd-4824-ad6b-aa3e7b206320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kowsher/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/kowsher/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from generator.modeling import PredictorCausalLM\n",
    "from generator.collator import DataCollator\n",
    "from generator import metrics\n",
    "from generator.training import GenTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fbe53f3-a24c-4c1c-855e-aa0efa56fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)  # Load configuration\n",
    "config.dense_representation = 10 \n",
    "config.pad_token_id = tokenizer.pad_token_id\n",
    "config.nub_of_token_generation = 19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49158043-e104-45c5-872e-507216095070",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PredictorCausalLM(config, num_labels=1)  # Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34698efb-cc78-404c-a93a-87e4c578c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leader\n",
    "\n",
    "leader.PEFT(model, method='column', rank=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1c3257-df7d-496f-82bf-525582c006fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollator(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a361a00b-2c37-4ccb-9020-f794e9fb88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Assuming `dataset` is your Hugging Face dataset\n",
    "# Example: Split into 80% train and 20% test\n",
    "split_ratio = 0.5  # Percentage of data for the test set\n",
    "\n",
    "split_datasets = test_data.train_test_split(test_size=split_ratio)\n",
    "\n",
    "# Access the splits\n",
    "val_dataset = split_datasets['train']\n",
    "test_dataset = split_datasets['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b568a9b1-4fa7-478e-ae4a-e8dbddf0df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kowsher/miniconda3/envs/LD/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import time\n",
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='dir',\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=3,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.00,\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    save_steps=10000000,\n",
    "    logging_steps=200,\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    lr_scheduler_type=\"cosine\",  # You can choose from 'linear', 'cosine', 'cosine_with_restarts', 'polynomial', etc.\n",
    "    warmup_steps=200,\n",
    ")\n",
    "\n",
    "compute_metrics = metrics.RegressionMetrics(tokenizer)\n",
    "trainer = GenTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    max_steps_for_sampling=500,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9e3504-1f95-4bfa-a033-47fccaffb12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-23 23:55:31,970] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kowsher/miniconda3/envs/LD/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/kowsher/miniconda3/envs/LD/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mahmedshuvo969\u001b[0m (\u001b[33mprojectstevens\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kowsher/investigation/wandb/run-20241223_235533-93ya8gxu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/projectstevens/huggingface/runs/93ya8gxu' target=\"_blank\">dir</a></strong> to <a href='https://wandb.ai/projectstevens/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/projectstevens/huggingface' target=\"_blank\">https://wandb.ai/projectstevens/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/projectstevens/huggingface/runs/93ya8gxu' target=\"_blank\">https://wandb.ai/projectstevens/huggingface/runs/93ya8gxu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2200' max='2200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2200/2200 20:49, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>7.727300</td>\n",
       "      <td>5.251891</td>\n",
       "      <td>1578.312694</td>\n",
       "      <td>66692033.078516</td>\n",
       "      <td>8166.519031</td>\n",
       "      <td>0.171605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.675300</td>\n",
       "      <td>4.295258</td>\n",
       "      <td>1626.993350</td>\n",
       "      <td>73864981.955163</td>\n",
       "      <td>8594.473920</td>\n",
       "      <td>0.082508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.905500</td>\n",
       "      <td>3.673838</td>\n",
       "      <td>420.096937</td>\n",
       "      <td>8593626.461886</td>\n",
       "      <td>2931.488779</td>\n",
       "      <td>0.893257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.320800</td>\n",
       "      <td>3.069591</td>\n",
       "      <td>3.398528</td>\n",
       "      <td>223.597757</td>\n",
       "      <td>14.953186</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.912500</td>\n",
       "      <td>2.848927</td>\n",
       "      <td>304.913706</td>\n",
       "      <td>18019517.086294</td>\n",
       "      <td>4244.940175</td>\n",
       "      <td>0.776176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.666500</td>\n",
       "      <td>2.714470</td>\n",
       "      <td>0.154822</td>\n",
       "      <td>1.777919</td>\n",
       "      <td>1.333386</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.509400</td>\n",
       "      <td>2.604989</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.021374</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.406500</td>\n",
       "      <td>2.549005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.352100</td>\n",
       "      <td>2.507626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.324800</td>\n",
       "      <td>2.503120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.313800</td>\n",
       "      <td>2.501434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2200, training_loss=3.3740604053844105, metrics={'train_runtime': 1251.9953, 'train_samples_per_second': 15.775, 'train_steps_per_second': 1.757, 'total_flos': 6318010758528.0, 'train_loss': 3.3740604053844105, 'epoch': 50.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2555faf1-543e-4657-b389-1d1afc5d3115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ypred, labels, mat = trainer.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f780a863-3f5d-4a46-af2a-ff4580f2a5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 2.3883354663848877,\n",
       " 'test_MAE': 1.6029100482051026e-07,\n",
       " 'test_MSE': 7.435143435576512e-13,\n",
       " 'test_RMSE': 8.622727779291489e-07,\n",
       " 'test_R2': 1.0,\n",
       " 'test_runtime': 10.1924,\n",
       " 'test_samples_per_second': 19.426,\n",
       " 'test_steps_per_second': 9.713}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e843b9a0-dc72-4c87-be03-7bcdb1ab1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicted_classes = np.argmax(ypred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5bd2eae-40fa-40c7-a19d-303486342ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed05bdc64f14fa7b5971b4b72b8e1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "k = 0\n",
    "ck = 0\n",
    "result = []\n",
    "truth = []\n",
    "for i in tqdm(range(len(predicted_classes))):\n",
    "    \n",
    "    try:\n",
    "        output = tokenizer.decode(predicted_classes[i])\n",
    "       \n",
    "        #print(output, float(re.findall(r'\\d+\\.\\d+|\\d+', output)[0])\n",
    "        result.append(float(re.findall(r'\\d+\\.\\d+|\\d+', output)[0]))\n",
    "        truth.append(test_dataset['labels'][i])\n",
    "    except:\n",
    "        ck = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "814bfb4f-bb20-460f-8afe-9ca8dad1e5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0 9.0\n",
      "0.5 0.5\n",
      "0.5 0.5\n",
      "10.0 10.0\n",
      "43.0 43.0\n",
      "9.8 9.8\n",
      "1792.0 1792.0\n",
      "17.0 17.0\n",
      "5110.0 5110.0\n",
      "12.3 12.3\n",
      "0.8888888888888888 0.8888888888888881\n",
      "13.0 13.0\n",
      "342.0 342.0\n",
      "10.46 10.46\n",
      "0.75 0.75\n",
      "6.6 6.6\n",
      "60.0 60.0\n",
      "14.0 14.0\n",
      "14.0 14.0\n",
      "2.0 2.0\n",
      "6.0 6.0\n",
      "88.0 88.0\n",
      "43.0 43.0\n",
      "1.3333333333333333 1.333333333333333\n",
      "0.8888888888888888 0.8888888888888881\n",
      "227.0 227.0\n",
      "4.0 4.0\n",
      "27004.0 27004.0\n",
      "60.0 60.0\n",
      "6.5 6.5\n",
      "0.8333333333333334 0.833333333333333\n",
      "0.8333333333333334 0.833333333333333\n",
      "0.6 0.6\n",
      "10.0 10.0\n",
      "7.0 7.0\n",
      "3120.0 3120.0\n",
      "0.2 0.2\n",
      "26.3 26.3\n",
      "46.0 46.0\n",
      "19.0 19.0\n",
      "48.0 48.0\n",
      "0.625 0.625\n",
      "8.0 8.0\n",
      "16.0 16.0\n",
      "11.0 11.0\n",
      "512.0 512.0\n",
      "13.0 13.0\n",
      "0.25 0.25\n",
      "25.31 25.31\n",
      "151.0 151.0\n",
      "100.0 100.0\n",
      "4.0 4.0\n",
      "8.0 8.0\n",
      "0.2 0.2\n",
      "14.0 14.0\n",
      "81.0 81.0\n",
      "0.75 0.75\n",
      "21.95 21.95\n",
      "0.25 0.25\n",
      "507.0 507.0\n",
      "44.0 44.0\n",
      "17.0 17.0\n",
      "7.26 7.26\n",
      "18.0 18.0\n",
      "22.0 22.0\n",
      "5.0 5.0\n",
      "13.0 13.0\n",
      "8317.0 8317.0\n",
      "16.0 16.0\n",
      "0.8 0.8\n",
      "559.0 559.0\n",
      "5.0 5.0\n",
      "971639.0 971639.0\n",
      "52.0 52.0\n",
      "0.9 0.9\n",
      "14.02 14.02\n",
      "0.6666666666666666 0.6666666666666661\n",
      "224.87 224.87\n",
      "41.0 41.0\n",
      "42.0 42.0\n",
      "13.0 13.0\n",
      "66.0 66.0\n",
      "48781.0 48781.0\n",
      "387.85 387.85\n",
      "0.6 0.6\n",
      "15.0 15.0\n",
      "0.75 0.75\n",
      "74.0 74.0\n",
      "20.52 20.52\n",
      "33.0 33.0\n",
      "20.0 20.0\n",
      "9.8 9.8\n",
      "19.02 19.02\n",
      "16.0 16.0\n",
      "29.0 29.0\n",
      "6755.0 6755.0\n",
      "6.0 6.0\n",
      "34.0 34.0\n",
      "37.0 37.0\n",
      "118558.0 118558.0\n",
      "0.1 0.1\n",
      "6279.0 6279.0\n",
      "7.0 7.0\n",
      "56.0 56.0\n",
      "14.75 14.75\n",
      "19.02 19.02\n",
      "1.0 1.0\n",
      "27.0 27.0\n",
      "18.0 18.0\n",
      "11.0 11.0\n",
      "77.0 77.0\n",
      "0.5 0.5\n",
      "0.4 0.4\n",
      "25.62 25.62\n",
      "11.0 11.0\n",
      "523.0 523.0\n",
      "141.54 141.54\n",
      "5.0 5.0\n",
      "12.0 12.0\n",
      "0.8 0.8\n",
      "71.0 71.0\n",
      "452.0 452.0\n",
      "15.1 15.1\n",
      "3.25 3.25\n",
      "13.0 13.0\n",
      "0.6666666666666666 0.6666666666666661\n",
      "74.0 74.0\n",
      "6699.0 6699.0\n",
      "0.6666666666666666 0.6666666666666661\n",
      "34.0 34.0\n",
      "0.5 0.5\n",
      "11.0 11.0\n",
      "0.3 0.3\n",
      "227.0 227.0\n",
      "0.375 0.375\n",
      "7790.0 7790.0\n",
      "63.0 63.0\n",
      "0.7 0.7\n",
      "16.0 16.0\n",
      "4.0 4.0\n",
      "21.0 21.0\n",
      "562.0 562.0\n",
      "5855.0 5855.0\n",
      "63.0 63.0\n",
      "5.333333333333333 5.333333333333333\n",
      "5935.0 5935.0\n",
      "2.0 2.0\n",
      "12.0 12.0\n",
      "50.0 50.0\n",
      "21.0 21.0\n",
      "9.0 9.0\n",
      "5.0 5.0\n",
      "10.333333333333334 10.333333333333334\n",
      "55.0 55.0\n",
      "65.0 65.0\n",
      "1.3333333333333333 1.333333333333333\n",
      "14696.0 14696.0\n",
      "58.0 58.0\n",
      "0.1 0.1\n",
      "9.0 9.0\n",
      "9.8 9.8\n",
      "98.0 98.0\n",
      "16.0 16.0\n",
      "212.0 212.0\n",
      "11.0 11.0\n",
      "100.0 100.0\n",
      "55.0 55.0\n",
      "158.35 158.35\n",
      "7.0 7.0\n",
      "9.43 9.43\n",
      "96.0 96.0\n",
      "11.0 11.0\n",
      "57.0 57.0\n",
      "23.0 23.0\n",
      "4.6 4.6\n",
      "54.0 54.0\n",
      "11.0 11.0\n",
      "106491.0 106491.0\n",
      "9.0 9.0\n",
      "0.3333333333333333 0.333333333333333\n",
      "2.75 2.75\n",
      "0.08 0.08\n",
      "21.0 21.0\n",
      "3.0 3.0\n",
      "3.0 3.0\n",
      "61.0 61.0\n",
      "16.0 16.0\n",
      "0.625 0.625\n",
      "4.0 4.0\n",
      "14.0 14.0\n",
      "5703.0 5703.0\n",
      "3.5 3.5\n",
      "6.0 6.0\n",
      "0.6 0.6\n",
      "35.52 35.52\n",
      "15.0 15.0\n",
      "111421.0 111421.0\n",
      "17.0 17.0\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(truth, result):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8702a-be9e-42e2-be0e-26ffb674ebf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
